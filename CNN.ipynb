{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convolutional Neural Network (CNN) for Image Classification",
   "id": "89062689b58ed041"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:10:43.447497Z",
     "start_time": "2025-07-29T09:10:43.441374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fontTools.misc.plistlib import end_date\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "id": "9d7e9d248522f25b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-29T09:10:44.002343Z",
     "start_time": "2025-07-29T09:10:43.987581Z"
    }
   },
   "source": "tf.__version__",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.2'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 1: Data Preprocessing",
   "id": "a95ac61f09bdc5f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing the Training set",
   "id": "6e3f4bb24975c034"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Apply transformations to the training set images to avoid overfitting\n",
    "# Also named as data augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,  # Normalize pixel values to [0, 1]; Feature scaling\n",
    "    shear_range = 0.2,  # Shear transformation; \n",
    "    zoom_range = 0.2,  # Zoom transformation\n",
    "    horizontal_flip = True  # Random horizontal flip\n",
    ")\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set',  # Path to the training set directory\n",
    "    target_size = (64, 64),  # Resize images to 64x64 pixels\n",
    "    batch_size = 32,  # Number of images to process in a batch\n",
    "    class_mode = 'binary'  # Use categorical labels for multi-class classification\n",
    ")\n"
   ],
   "id": "8e141f51e7311a4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing the Test set",
   "id": "69d22077c5e82549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:10:45.312852Z",
     "start_time": "2025-07-29T08:18:02.810187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)  # Normalize pixel values for the test set\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set',  # Path to the test set directory\n",
    "    target_size = (64, 64),  # Resize images to 64x64\n",
    "    batch_size = 32,  # Number of images to process in a batch\n",
    "    class_mode = 'binary'  # Use categorical labels for multi-class classification\n",
    ")\n"
   ],
   "id": "2a1ab44f236d07c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 2: Building the CNN",
   "id": "60ddaf13ce19fb8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing the CNN",
   "id": "3033624992afb802"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:10:45.554794Z",
     "start_time": "2025-07-29T09:10:45.546697Z"
    }
   },
   "cell_type": "code",
   "source": "cnn = tf.keras.models.Sequential()  # Create a sequential model for the CNN\n",
   "id": "8a8d9746250b7c20",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 1: Convolution",
   "id": "2e55e62b754e3d3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(\n",
    "    filters = 32,  # Number of filters in the convolutional layer because it is the first layer\n",
    "    kernel_size = (3, 3),  # Size of the convolutional kernel\n",
    "    activation = 'relu',  # Activation function for the layer we choose ReLU because it is a common choice for CNNs\n",
    "    input_shape = (64, 64, 3)  # Input shape of the images (64x64 pixels, 3 color channels) we choose 3 because the images are RGB images and 64x64 is the size of the images\n",
    "    \n",
    "))"
   ],
   "id": "73626150eef3678d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2: Pooling",
   "id": "a8e85f66870a1fd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:20:37.133012Z",
     "start_time": "2025-07-29T08:20:37.122150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size = 2, # Size of the pooling window, we choose 2x2 because it is a common choice for CNNs, we take 2x2 frames from the feature map and take the maximum value from each frame to reduce the size of the feature map\n",
    "    \n",
    "    strides = 2  # Stride size, we choose 2 because it is a common choice for CNNs, it means that we move the pooling window by 2 pixels in both directions\n",
    "    \n",
    "))"
   ],
   "id": "4d23a0a1200d2904",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding a convolutional layer ",
   "id": "d42f76a4ef8f5700"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:21:07.900722Z",
     "start_time": "2025-07-29T08:21:07.870139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(\n",
    "    filters = 32,  # Number of filters in the convolutional layer\n",
    "    kernel_size = (3, 3),  # Size of the convolutional kernel\n",
    "    activation = 'relu'  # Activation function for the layer\n",
    "))\n",
    "# Adding a pooling layer\n",
    "cnn.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size = 2,  # Size of the pooling window\n",
    "    strides = 2  # Stride size\n",
    "))"
   ],
   "id": "e04e80f6c6c2db70",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 3: Flattening",
   "id": "48c27f5cf3badff6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:22:09.088540Z",
     "start_time": "2025-07-29T08:22:09.074957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.add(tf.keras.layers.Flatten())  # Flatten the feature maps to a 1D vector for the fully connected layer\n",
    "# Flattening is necessary to convert the 2D feature maps into a 1D vector"
   ],
   "id": "2246fd524cacf910",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 4: Full Connection",
   "id": "4be31172e9118c07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:27:22.951736Z",
     "start_time": "2025-07-29T08:27:22.920048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.add(tf.keras.layers.Dense(\n",
    "    units = 128,  # Number of neurons in the fully connected layer\n",
    "    activation = 'relu'  # Activation function for the layer\n",
    "))\n"
   ],
   "id": "3f95d695776b2133",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 5: Output Layer",
   "id": "6a3169f976c88a28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:27:23.815249Z",
     "start_time": "2025-07-29T08:27:23.791038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.add(tf.keras.layers.Dense(\n",
    "    units = 1,  # Number of output neurons (1 for binary classification)\n",
    "    activation = 'sigmoid'  # Sigmoid activation function for binary classification\n",
    "))"
   ],
   "id": "4d7f7228ce6e6b29",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Part 3: Training the CNN",
   "id": "f725923b84d2aa97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compiling the CNN and evaluating the model",
   "id": "a0397288738814bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:27:27.222115Z",
     "start_time": "2025-07-29T08:27:27.211222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.compile(\n",
    "    optimizer = 'adam',  # Optimizer for the model, we choose Adam because it is a common choice for CNNs\n",
    "    loss = 'binary_crossentropy',  # Loss function for binary classification\n",
    "    metrics = ['accuracy']  # Metrics to evaluate the model\n",
    ")"
   ],
   "id": "e426b47e570fce2e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training the CNN on the training set and evaluating it on the test set",
   "id": "3602e490ee3f069"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cnn.fit(\n",
    "    x = training_set,  # Training data\n",
    "    validation_data = test_set,  # Validation data\n",
    "    epochs = 25  # Number of epochs to train the model\n",
    ")"
   ],
   "id": "63e34ea9382d1657",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Making a single prediction",
   "id": "f51b4c7ea7a4cf8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T09:05:14.439218Z",
     "start_time": "2025-07-29T09:05:14.320065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('/Users/octaviodaniel/Desktop/c o d e/DATA SCIENCE/ML A-Z/Machine-Learning-A-Z-Codes-Datasets/Part 8 - Deep Learning/Section 40 - Convolutional Neural Networks (CNN)/Python/dataset/test_set/dogs/dog.4003.jpg', target_size=(64, 64))  # Load the image and resize it to 64x64 pixels\n",
    "\n",
    "test_image = image.img_to_array(test_image)  # Convert the image to a numpy array\n",
    "\n",
    "test_image = np.expand_dims(test_image, axis=0)  # Add a batch dimension\n",
    "\n",
    "result = cnn.predict(test_image)  # Make a prediction on the image\n",
    "\n",
    "training_set.class_indices  # Get the class indices from the training set\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'  # If the prediction is 1, it is a dog\n",
    "else:\n",
    "    prediction = 'cat'  # If the prediction is 0, it is a cat \n",
    "    \n",
    "print(prediction)  # Print the prediction"
   ],
   "id": "f29bcdec53822a92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "dog\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
